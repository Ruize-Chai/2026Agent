# 后端开发基本策划

##1.workflow流程控制基本架构

(1)workflow的节点（note）作为类存在。它有一些核心方法可以调用。

(2)workflow需要一个全局的数据存储池，它包括了一个量值列表（提供给前端），和一个存储区域。它的引用作为参数传入节点，
节点可以读写这些信息。流程的流向，和数据的流向是分离的。

(3)workflow的流程是**软编码的**,即它的逻辑结构，可以由一套软编码规则来确定，而不需要每一次都在代码层确定。所以，这里需要一套软编码规则，它可以把一个workflow的编码（通常是一个有结构的数据体，例如(json)Dict),
对应为一套workflow工作流程，包括节点信息和逻辑结构（本质上也是节点)。逻辑结构包括顺序/判断/迭代等,每种操作类型可以称为**Skill**.**暂时不要支持多线异步执行**

(4)上述过程需要一个函数(Skill Interpreter)，它可以按照（3）所述的规则，执行workflow的代码调度。这是workflow的主函数.建议内部抽象化，便于二次开发.

(5)workflow的存储和传递同样使用上述软编码规则，并作为协议(Skill Protocol)在Agent、前端之间通信。

(6)前端应该写一个流程创建的页面.
##2.关于Skill Protocol
(1)它是由节点构成的序列.

(2)它们的第一个键是主键.

(3)由于一般来说无论逻辑节点还是事务节点都是单向流动的，结构相对简单,所以可以在后面2~3个键里面存输入输出节点的主键还有类型id

(4)后面的键由节点自身Skill类型的格式决定，存一些节点参数(比如LLM的模型回答参数、API KEY、上下文,或者迭代模块的迭代次数等等).

##3.关于Json
(1)写一个`json_utils.py`,功能是完成对每种格式化消息的读/写/校验/序列化/反序列化

(2)关于Json包在HTTP协议的传递，参看[Requests](https://requests.pythonlang.cn/en/latest/user/quickstart/)

(3)关于json和protocol,还有个想法，必须为每种模块配置独特的类型id、json(schema)、json_utils,那么，后人如果要新增添插件，直接在我们的拓展id字段上添加就可以了。

##4.关于OpenAI SDK
(1)构建一个专门的Json_dict，这个可以作为与BASE(endpoint)间交互的核心数据依据.

(2)对于兼容OpenAI SDK接口的AI大模型支持网站(例如七牛云)可以直接使用我们的OpenAI SDK取包接口.

(3)前端应当写一个页面维护API注册表，包括每一个API密钥及其对应BASE endpoint的url.也用json

##5.关于日志体系和异常处理
（1）日志的核心操作就是写文件。每一个操作完成后必须记录在控制台上和日志里.

（2）尝试给错误进行分级分类编码。(比如按照报错位置进行标记)

（3）异常处理。对于极其严重的问题(FATAL),我们直接退出程序（比如启动异常）,对于不太严重的问题，我们可以在可重试操作中（比如HTTP没请求上)设置重试并报错(ERROR),或者直接忽略(IGNORE/DISCARD).

##6.关于与前端通信：通过FastAPI发布json包.(可能也会用requests, 但是肯定是json包和HTTP）

##7.关于Skill Interpreter
(1)本质上是按照protocol决定的流向执行流程。注意：流程的流向和数据的流向是分离的。

(2)先找到对应的模块里面对应的节点类，然后把后面自定义字段里面的东西丢给节点，拼装一个由节点实例构成的list

(3)然后根据protocol的顺序调用list做事就可以了.(实现方法：在每一个skill类里面写一个函数，然后返回下一个节点的id)

##8.async matrix





